{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "3.FDA Project_Simran.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eqopdUGXhqyn"
      },
      "source": [
        "# LSTM (Long Short Term Memory Transformer) model for Sentiment Analysis"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dXehGRntffe1",
        "outputId": "fee14279-3b95-452f-97f2-c964592083a7"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from numpy import percentile\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import matplotlib\n",
        "import tweepy\n",
        "from textblob import TextBlob\n",
        "import re # for regular expressions\n",
        "import pandas as pd \n",
        "pd.set_option(\"display.max_colwidth\", 200) \n",
        "import string\n",
        "import requests\n",
        "import folium\n",
        "from folium import plugins\n",
        "from folium.plugins import HeatMap\n",
        "import nltk # for text manipulation\n",
        "from nltk.stem.porter import *\n",
        "from nltk.tokenize import TweetTokenizer\n",
        "from nltk.corpus import stopwords\n",
        "from nltk import pos_tag, ne_chunk\n",
        "from nltk.sentiment.vader import SentimentIntensityAnalyzer as sid\n",
        "from wordcloud import WordCloud\n",
        "from tqdm import tqdm, notebook\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
        "from tqdm import tqdm\n",
        "from gensim.models.doc2vec import LabeledSentence\n",
        "import gensim\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from scipy import stats \n",
        "from sklearn import metrics \n",
        "from sklearn.metrics import mean_squared_error,mean_absolute_error, make_scorer,classification_report,confusion_matrix,accuracy_score,roc_auc_score,roc_curve\n",
        "from sklearn.model_selection import train_test_split,cross_val_score,KFold\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import f1_score"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/nltk/twitter/__init__.py:20: UserWarning: The twython library has not been installed. Some functionality from the twitter package will not be available.\n",
            "  warnings.warn(\"The twython library has not been installed. \"\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 820
        },
        "id": "BUX5GXXLfmeC",
        "outputId": "b18c200b-92a0-4ef7-b803-bb87f5f1b603"
      },
      "source": [
        "df=pd.read_csv(\"https://raw.githubusercontent.com/gabrielpreda/covid-19-tweets/master/covid19_tweets.csv\")\n",
        "df.head()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>user_name</th>\n",
              "      <th>user_location</th>\n",
              "      <th>user_description</th>\n",
              "      <th>user_created</th>\n",
              "      <th>user_followers</th>\n",
              "      <th>user_friends</th>\n",
              "      <th>user_favourites</th>\n",
              "      <th>user_verified</th>\n",
              "      <th>date</th>\n",
              "      <th>text</th>\n",
              "      <th>hashtags</th>\n",
              "      <th>source</th>\n",
              "      <th>is_retweet</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>·èâ·é•‚òª’¨ÍÇÖœÆ</td>\n",
              "      <td>astroworld</td>\n",
              "      <td>wednesday addams as a disney princess keepin it [Ã≤ÃÖ$Ã≤ÃÖ(Ã≤ÃÖŒπŒøŒøÃ≤ÃÖ)Ã≤ÃÖ$Ã≤ÃÖ] üë∏üèªüíö‚ôäÔ∏èüßÄüåµüåÉüåô</td>\n",
              "      <td>2017-05-26 05:46:42</td>\n",
              "      <td>624</td>\n",
              "      <td>950</td>\n",
              "      <td>18775</td>\n",
              "      <td>False</td>\n",
              "      <td>2020-07-25 12:27:21</td>\n",
              "      <td>If I smelled the scent of hand sanitizers today on someone in the past, I would think they were so intoxicated that‚Ä¶ https://t.co/QZvYbrOgb0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Twitter for iPhone</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Tom Basile üá∫üá∏</td>\n",
              "      <td>New York, NY</td>\n",
              "      <td>Husband, Father, Columnist &amp; Commentator. Author of Tough Sell: Fighting the Media War in Iraq. Bush Admin Alum. Newsmax Contributor. Fmr Exec Dir NYSGOP</td>\n",
              "      <td>2009-04-16 20:06:23</td>\n",
              "      <td>2253</td>\n",
              "      <td>1677</td>\n",
              "      <td>24</td>\n",
              "      <td>True</td>\n",
              "      <td>2020-07-25 12:27:17</td>\n",
              "      <td>Hey @Yankees @YankeesPR and @MLB - wouldn't it have made more sense to have the players pay their respects to the A‚Ä¶ https://t.co/1QvW0zgyPu</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Twitter for Android</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Time4fisticuffs</td>\n",
              "      <td>Pewee Valley, KY</td>\n",
              "      <td>#Christian #Catholic #Conservative #Reagan #Republican #Capitalist; Sports lover - #BBN #Cincinnati #Reds #Bengals #Trump2020</td>\n",
              "      <td>2009-02-28 18:57:41</td>\n",
              "      <td>9275</td>\n",
              "      <td>9525</td>\n",
              "      <td>7254</td>\n",
              "      <td>False</td>\n",
              "      <td>2020-07-25 12:27:14</td>\n",
              "      <td>@diane3443 @wdunlap @realDonaldTrump Trump never once claimed #COVID19 was a hoax. We all claim that this effort to‚Ä¶ https://t.co/Jkk8vHWHb3</td>\n",
              "      <td>['COVID19']</td>\n",
              "      <td>Twitter for Android</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ethel mertz</td>\n",
              "      <td>Stuck in the Middle</td>\n",
              "      <td>#Browns #Indians #ClevelandProud #[]_[] #Cavs #Resist</td>\n",
              "      <td>2019-03-07 01:45:06</td>\n",
              "      <td>197</td>\n",
              "      <td>987</td>\n",
              "      <td>1488</td>\n",
              "      <td>False</td>\n",
              "      <td>2020-07-25 12:27:10</td>\n",
              "      <td>@brookbanktv The one gift #COVID19 has give me is an appreciation for the simple things that were always around me‚Ä¶ https://t.co/Z0pOAlFXcW</td>\n",
              "      <td>['COVID19']</td>\n",
              "      <td>Twitter for iPhone</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>DIPR-J&amp;K</td>\n",
              "      <td>Jammu and Kashmir</td>\n",
              "      <td>üñäÔ∏èOfficial Twitter handle of Department of Information and Public Relations, Govt of Jammu &amp; Kashmir</td>\n",
              "      <td>2017-02-12 06:45:15</td>\n",
              "      <td>101009</td>\n",
              "      <td>168</td>\n",
              "      <td>101</td>\n",
              "      <td>False</td>\n",
              "      <td>2020-07-25 12:27:08</td>\n",
              "      <td>25 July : Media Bulletin on Novel #CoronaVirusUpdates #COVID19 \\n@kansalrohit69 @DrSyedSehrish @airnewsalerts @ANI‚Ä¶ https://t.co/MN0EEcsJHh</td>\n",
              "      <td>['CoronaVirusUpdates', 'COVID19']</td>\n",
              "      <td>Twitter for Android</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         user_name         user_location  ...               source is_retweet\n",
              "0           ·èâ·é•‚òª’¨ÍÇÖœÆ            astroworld  ...   Twitter for iPhone      False\n",
              "1    Tom Basile üá∫üá∏          New York, NY  ...  Twitter for Android      False\n",
              "2  Time4fisticuffs      Pewee Valley, KY  ...  Twitter for Android      False\n",
              "3      ethel mertz  Stuck in the Middle   ...   Twitter for iPhone      False\n",
              "4         DIPR-J&K     Jammu and Kashmir  ...  Twitter for Android      False\n",
              "\n",
              "[5 rows x 13 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 362
        },
        "id": "F_n6TcYMft3e",
        "outputId": "e2af6c1d-a410-433b-af49-02eedaac8677"
      },
      "source": [
        "# write function for removing @user\n",
        "def remove_pattern(input_txt, pattern):\n",
        "    r = re.findall(pattern, input_txt)\n",
        "    for i in r:\n",
        "        input_txt = re.sub(i,'',input_txt)\n",
        "    return input_txt\n",
        "# create new column with removed @user\n",
        "df['clean_text'] = np.vectorize(remove_pattern)(df['text'], '@[\\w]*')\n",
        "df.head(2)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>user_name</th>\n",
              "      <th>user_location</th>\n",
              "      <th>user_description</th>\n",
              "      <th>user_created</th>\n",
              "      <th>user_followers</th>\n",
              "      <th>user_friends</th>\n",
              "      <th>user_favourites</th>\n",
              "      <th>user_verified</th>\n",
              "      <th>date</th>\n",
              "      <th>text</th>\n",
              "      <th>hashtags</th>\n",
              "      <th>source</th>\n",
              "      <th>is_retweet</th>\n",
              "      <th>clean_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>·èâ·é•‚òª’¨ÍÇÖœÆ</td>\n",
              "      <td>astroworld</td>\n",
              "      <td>wednesday addams as a disney princess keepin it [Ã≤ÃÖ$Ã≤ÃÖ(Ã≤ÃÖŒπŒøŒøÃ≤ÃÖ)Ã≤ÃÖ$Ã≤ÃÖ] üë∏üèªüíö‚ôäÔ∏èüßÄüåµüåÉüåô</td>\n",
              "      <td>2017-05-26 05:46:42</td>\n",
              "      <td>624</td>\n",
              "      <td>950</td>\n",
              "      <td>18775</td>\n",
              "      <td>False</td>\n",
              "      <td>2020-07-25 12:27:21</td>\n",
              "      <td>If I smelled the scent of hand sanitizers today on someone in the past, I would think they were so intoxicated that‚Ä¶ https://t.co/QZvYbrOgb0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Twitter for iPhone</td>\n",
              "      <td>False</td>\n",
              "      <td>If I smelled the scent of hand sanitizers today on someone in the past, I would think they were so intoxicated that‚Ä¶ https://t.co/QZvYbrOgb0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Tom Basile üá∫üá∏</td>\n",
              "      <td>New York, NY</td>\n",
              "      <td>Husband, Father, Columnist &amp; Commentator. Author of Tough Sell: Fighting the Media War in Iraq. Bush Admin Alum. Newsmax Contributor. Fmr Exec Dir NYSGOP</td>\n",
              "      <td>2009-04-16 20:06:23</td>\n",
              "      <td>2253</td>\n",
              "      <td>1677</td>\n",
              "      <td>24</td>\n",
              "      <td>True</td>\n",
              "      <td>2020-07-25 12:27:17</td>\n",
              "      <td>Hey @Yankees @YankeesPR and @MLB - wouldn't it have made more sense to have the players pay their respects to the A‚Ä¶ https://t.co/1QvW0zgyPu</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Twitter for Android</td>\n",
              "      <td>False</td>\n",
              "      <td>Hey  PR and  - wouldn't it have made more sense to have the players pay their respects to the A‚Ä¶ https://t.co/1QvW0zgyPu</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       user_name  ...                                                                                                                                    clean_text\n",
              "0         ·èâ·é•‚òª’¨ÍÇÖœÆ  ...  If I smelled the scent of hand sanitizers today on someone in the past, I would think they were so intoxicated that‚Ä¶ https://t.co/QZvYbrOgb0\n",
              "1  Tom Basile üá∫üá∏  ...                      Hey  PR and  - wouldn't it have made more sense to have the players pay their respects to the A‚Ä¶ https://t.co/1QvW0zgyPu\n",
              "\n",
              "[2 rows x 14 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 643
        },
        "id": "xKJlHysSfyl0",
        "outputId": "0901e67d-daa8-457d-d1a3-baabbaa770e3"
      },
      "source": [
        "import re\n",
        "df['clean_text'] = df['clean_text'].apply(lambda x: re.split('https:\\/\\/.*', str(x))[0])\n",
        "df.head(3)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>user_name</th>\n",
              "      <th>user_location</th>\n",
              "      <th>user_description</th>\n",
              "      <th>user_created</th>\n",
              "      <th>user_followers</th>\n",
              "      <th>user_friends</th>\n",
              "      <th>user_favourites</th>\n",
              "      <th>user_verified</th>\n",
              "      <th>date</th>\n",
              "      <th>text</th>\n",
              "      <th>hashtags</th>\n",
              "      <th>source</th>\n",
              "      <th>is_retweet</th>\n",
              "      <th>clean_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>·èâ·é•‚òª’¨ÍÇÖœÆ</td>\n",
              "      <td>astroworld</td>\n",
              "      <td>wednesday addams as a disney princess keepin it [Ã≤ÃÖ$Ã≤ÃÖ(Ã≤ÃÖŒπŒøŒøÃ≤ÃÖ)Ã≤ÃÖ$Ã≤ÃÖ] üë∏üèªüíö‚ôäÔ∏èüßÄüåµüåÉüåô</td>\n",
              "      <td>2017-05-26 05:46:42</td>\n",
              "      <td>624</td>\n",
              "      <td>950</td>\n",
              "      <td>18775</td>\n",
              "      <td>False</td>\n",
              "      <td>2020-07-25 12:27:21</td>\n",
              "      <td>If I smelled the scent of hand sanitizers today on someone in the past, I would think they were so intoxicated that‚Ä¶ https://t.co/QZvYbrOgb0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Twitter for iPhone</td>\n",
              "      <td>False</td>\n",
              "      <td>If I smelled the scent of hand sanitizers today on someone in the past, I would think they were so intoxicated that‚Ä¶</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Tom Basile üá∫üá∏</td>\n",
              "      <td>New York, NY</td>\n",
              "      <td>Husband, Father, Columnist &amp; Commentator. Author of Tough Sell: Fighting the Media War in Iraq. Bush Admin Alum. Newsmax Contributor. Fmr Exec Dir NYSGOP</td>\n",
              "      <td>2009-04-16 20:06:23</td>\n",
              "      <td>2253</td>\n",
              "      <td>1677</td>\n",
              "      <td>24</td>\n",
              "      <td>True</td>\n",
              "      <td>2020-07-25 12:27:17</td>\n",
              "      <td>Hey @Yankees @YankeesPR and @MLB - wouldn't it have made more sense to have the players pay their respects to the A‚Ä¶ https://t.co/1QvW0zgyPu</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Twitter for Android</td>\n",
              "      <td>False</td>\n",
              "      <td>Hey  PR and  - wouldn't it have made more sense to have the players pay their respects to the A‚Ä¶</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Time4fisticuffs</td>\n",
              "      <td>Pewee Valley, KY</td>\n",
              "      <td>#Christian #Catholic #Conservative #Reagan #Republican #Capitalist; Sports lover - #BBN #Cincinnati #Reds #Bengals #Trump2020</td>\n",
              "      <td>2009-02-28 18:57:41</td>\n",
              "      <td>9275</td>\n",
              "      <td>9525</td>\n",
              "      <td>7254</td>\n",
              "      <td>False</td>\n",
              "      <td>2020-07-25 12:27:14</td>\n",
              "      <td>@diane3443 @wdunlap @realDonaldTrump Trump never once claimed #COVID19 was a hoax. We all claim that this effort to‚Ä¶ https://t.co/Jkk8vHWHb3</td>\n",
              "      <td>['COVID19']</td>\n",
              "      <td>Twitter for Android</td>\n",
              "      <td>False</td>\n",
              "      <td>Trump never once claimed #COVID19 was a hoax. We all claim that this effort to‚Ä¶</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         user_name  ...                                                                                                             clean_text\n",
              "0           ·èâ·é•‚òª’¨ÍÇÖœÆ  ...  If I smelled the scent of hand sanitizers today on someone in the past, I would think they were so intoxicated that‚Ä¶ \n",
              "1    Tom Basile üá∫üá∏  ...                      Hey  PR and  - wouldn't it have made more sense to have the players pay their respects to the A‚Ä¶ \n",
              "2  Time4fisticuffs  ...                                       Trump never once claimed #COVID19 was a hoax. We all claim that this effort to‚Ä¶ \n",
              "\n",
              "[3 rows x 14 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P28pe1dXfzWD"
      },
      "source": [
        "# remove special characters, numbers, punctuations\n",
        "df['clean_text'] = df['clean_text'].str.replace('[^a-zA-Z#]+',' ')"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 429
        },
        "id": "hVHzodfOf3f0",
        "outputId": "4742ee5f-6379-45cb-a0bf-b512eacbd38c"
      },
      "source": [
        "# remove short words\n",
        "df['clean_text'] = df['clean_text'].apply(lambda x: ' '.join([w for w in x.split() if len(w) > 2]))\n",
        "df.head(2)\n",
        "# create new variable tokenized tweet \n",
        "tokenized_tweet = df['clean_text'].apply(lambda x: x.split())\n",
        "df.head(2)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>user_name</th>\n",
              "      <th>user_location</th>\n",
              "      <th>user_description</th>\n",
              "      <th>user_created</th>\n",
              "      <th>user_followers</th>\n",
              "      <th>user_friends</th>\n",
              "      <th>user_favourites</th>\n",
              "      <th>user_verified</th>\n",
              "      <th>date</th>\n",
              "      <th>text</th>\n",
              "      <th>hashtags</th>\n",
              "      <th>source</th>\n",
              "      <th>is_retweet</th>\n",
              "      <th>clean_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>·èâ·é•‚òª’¨ÍÇÖœÆ</td>\n",
              "      <td>astroworld</td>\n",
              "      <td>wednesday addams as a disney princess keepin it [Ã≤ÃÖ$Ã≤ÃÖ(Ã≤ÃÖŒπŒøŒøÃ≤ÃÖ)Ã≤ÃÖ$Ã≤ÃÖ] üë∏üèªüíö‚ôäÔ∏èüßÄüåµüåÉüåô</td>\n",
              "      <td>2017-05-26 05:46:42</td>\n",
              "      <td>624</td>\n",
              "      <td>950</td>\n",
              "      <td>18775</td>\n",
              "      <td>False</td>\n",
              "      <td>2020-07-25 12:27:21</td>\n",
              "      <td>If I smelled the scent of hand sanitizers today on someone in the past, I would think they were so intoxicated that‚Ä¶ https://t.co/QZvYbrOgb0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Twitter for iPhone</td>\n",
              "      <td>False</td>\n",
              "      <td>smelled the scent hand sanitizers today someone the past would think they were intoxicated that</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Tom Basile üá∫üá∏</td>\n",
              "      <td>New York, NY</td>\n",
              "      <td>Husband, Father, Columnist &amp; Commentator. Author of Tough Sell: Fighting the Media War in Iraq. Bush Admin Alum. Newsmax Contributor. Fmr Exec Dir NYSGOP</td>\n",
              "      <td>2009-04-16 20:06:23</td>\n",
              "      <td>2253</td>\n",
              "      <td>1677</td>\n",
              "      <td>24</td>\n",
              "      <td>True</td>\n",
              "      <td>2020-07-25 12:27:17</td>\n",
              "      <td>Hey @Yankees @YankeesPR and @MLB - wouldn't it have made more sense to have the players pay their respects to the A‚Ä¶ https://t.co/1QvW0zgyPu</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Twitter for Android</td>\n",
              "      <td>False</td>\n",
              "      <td>Hey and wouldn have made more sense have the players pay their respects the</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       user_name  ...                                                                                       clean_text\n",
              "0         ·èâ·é•‚òª’¨ÍÇÖœÆ  ...  smelled the scent hand sanitizers today someone the past would think they were intoxicated that\n",
              "1  Tom Basile üá∫üá∏  ...                      Hey and wouldn have made more sense have the players pay their respects the\n",
              "\n",
              "[2 rows x 14 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LZN6IFvWf_xz"
      },
      "source": [
        "from nltk.stem.porter import *\n",
        "stemmer = PorterStemmer()\n",
        "# apply stemmer for tokenized_tweet\n",
        "tokenized_tweet = tokenized_tweet.apply(lambda x: [stemmer.stem(i) for i in x])"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b2ciNzBegERK"
      },
      "source": [
        "# join tokens into one sentence\n",
        "for i in range(len(tokenized_tweet)):\n",
        "    tokenized_tweet[i] = ' '.join(tokenized_tweet[i])\n",
        "# change df['clean_text'] to tokenized_tweet"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ka2Zl5hUgHzm"
      },
      "source": [
        "df['clean_text']  = tokenized_tweet"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_LHpTfb1gKm-",
        "outputId": "791031d7-9b3e-4543-ba1c-4fc77704726e"
      },
      "source": [
        "nltk.download('stopwords')"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hu9ygAZ8gORm"
      },
      "source": [
        "from nltk.corpus import stopwords\n",
        "stop = stopwords.words('english')"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nu_QVZN6gQUf",
        "outputId": "f10e32c5-c812-4eb5-d01a-8191453e2e0f"
      },
      "source": [
        "df['clean_text'].apply(lambda x: [item for item in x if item not in stop])"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0                           [e, l, l,  , h, e,  , c, e, n,  , h, n,  , n,  ,  , e, n,  , h, e,  , p,  , w, u, l,  , h, n, k,  , h, e,  , w, e, r, e,  , n, x,  , h]\n",
              "1                  [h, e,  , n,  , w, u, l, n,  , h, v, e,  , e,  , r, e,  , e, n,  , h, v, e,  , h, e,  , p, l, e, r,  , p,  , h, e, r,  , r, e, p, e, c,  , h, e]\n",
              "2                                             [r, u, p,  , n, e, v, e, r,  , n, c,  , c, l,  , #, c, v,  , w,  , h, x,  , l, l,  , c, l,  , h,  , h,  , e, f, f, r]\n",
              "3         [h, e,  , n, e,  , g, f,  , #, c, v,  , h,  , g, v, e,  , p, p, r, e, c,  , f, r,  , h, e,  , p, l,  , h, n, g,  , h,  , w, e, r, e,  , l, w,  , r, u, n]\n",
              "4                                                                     [j, u, l,  , e,  , b, u, l, l, e, n,  , n, v, e, l,  , #, c, r, n, v, r, u, u, p,  , #, c, v]\n",
              "                                                                                    ...                                                                            \n",
              "179103                                                             [h, n, k,  , f, r,  , n, n,  , f, r,  , h, e,  , #, w, e, r, k,  , c, h, l, l, e, n, g,  , n, n]\n",
              "179104                                                                                                                [h, e,  , e, r,  , n, n,  , l, l,  , #, c, v]\n",
              "179105             [p, w, e, r,  , p, n,  , j, u, n,  , l, u, c, e, n,  , r, b, u,  , h, e,  , g, r, n, p, r,  , w, h,  , e,  , c, v,  , n,  , h, e,  , g, r, n, c]\n",
              "179106                                                 [r, e,  , h, n,  , u, e, n,  , e,  , p,  , f, r,  , #, c, v,  , j, r,  , u, n, v, e, r,  , b, c,  , n, e, w]\n",
              "179107                                                                                                                            [p,  , w, h, e, n,  , e, e,  , p]\n",
              "Name: clean_text, Length: 179108, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XLeiblNWgSjF"
      },
      "source": [
        "#creates a function that determines subjectivity and polarity from the textblob package\n",
        "def getTextSubjectivity(clean_text):\n",
        "    return TextBlob(clean_text).sentiment.subjectivity\n",
        "def getTextPolarity(clean_text):\n",
        "    return TextBlob(clean_text).sentiment.polarity\n",
        "#applies these functions to the dataframe\n",
        "df['Subjectivity'] = df['clean_text'].apply(getTextSubjectivity)\n",
        "df['Polarity'] = df['clean_text'].apply(getTextPolarity)\n",
        "#builds a function to calculate and categorize each tweet as Negative, Neutral, and Positive\n",
        "def getTextAnalysis(a):\n",
        "    if a < 0:\n",
        "        return \"Negative\"\n",
        "    elif a == 0:\n",
        "        return \"Neutral\"\n",
        "    else:\n",
        "        return \"Positive\"\n",
        "#creates another column called Score and applies the function to the dataframe\n",
        "df['Score'] = df['Polarity'].apply(getTextAnalysis)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Spfcc-PogW5g"
      },
      "source": [
        "new_df=df[['clean_text','Score']]"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S48DPundga9y"
      },
      "source": [
        "data=new_df.head(20000)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oAwo3308ghTn"
      },
      "source": [
        "## LSTM Neural Network using Keras"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DH29CkOhht5D"
      },
      "source": [
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Embedding, LSTM, SpatialDropout1D\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.utils.np_utils import to_categorical\n",
        "from sklearn.utils import resample\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.metrics import confusion_matrix,classification_report"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7myBqMCsl18i"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train,valid = train_test_split(data,test_size = 0.3,random_state=0,stratify = data.Score.values) #stratification means that the train_test_split method returns training and test subsets that have the same proportions of class labels as the input dataset."
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rYr2rH6Jll-k"
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from nltk.corpus import stopwords\n",
        "stop = list(stopwords.words('english'))\n",
        "vectorizer = CountVectorizer(decode_error = 'replace',stop_words = stop)\n",
        "\n",
        "X_train = vectorizer.fit_transform(train.clean_text.values)\n",
        "X_valid = vectorizer.transform(valid.clean_text.values)\n",
        "\n",
        "y_train = train.Score.values\n",
        "y_valid = valid.Score.values"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0fSCpFdDfAVm",
        "outputId": "77ee5839-3e8d-40b4-81a3-0b8dbec8276e"
      },
      "source": [
        "# model\n",
        "embed_dim = 128\n",
        "lstm_out = 192\n",
        "max_fatures = 2000\n",
        "model = Sequential()\n",
        "model.add(Embedding(max_fatures, embed_dim,input_length = X_train.shape[1]))\n",
        "model.add(SpatialDropout1D(0.4))\n",
        "model.add(LSTM(lstm_out, dropout=0.4, recurrent_dropout=0.4))\n",
        "model.add(Dense(2,activation='softmax'))\n",
        "model.compile(loss = 'categorical_crossentropy', optimizer='adam',metrics = ['accuracy'])\n",
        "print(model.summary())"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, 15056, 128)        256000    \n",
            "_________________________________________________________________\n",
            "spatial_dropout1d (SpatialDr (None, 15056, 128)        0         \n",
            "_________________________________________________________________\n",
            "lstm (LSTM)                  (None, 192)               246528    \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 2)                 386       \n",
            "=================================================================\n",
            "Total params: 502,914\n",
            "Trainable params: 502,914\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uSiG9nCZn2jO",
        "outputId": "0f580c5a-885c-4757-fd79-c2542c705c62"
      },
      "source": [
        "from sklearn.neural_network import MLPClassifier\n",
        "mlp = MLPClassifier(hidden_layer_sizes=(10, 10, 10), max_iter=1000)\n",
        "mlp.fit(X_train, y_train)\n",
        "predictions = mlp.predict(X_valid)\n",
        "accuracy = accuracy_score(y_valid,predictions)\n",
        "print(\"Training accuracy Score    : \",mlp.score(X_train,y_train))\n",
        "print(\"Validation accuracy Score : \",accuracy )\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "print(classification_report(y_valid,predictions))"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training accuracy Score    :  1.0\n",
            "Validation accuracy Score :  0.8285\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    Negative       0.77      0.68      0.72       875\n",
            "     Neutral       0.85      0.89      0.87      3056\n",
            "    Positive       0.82      0.80      0.81      2069\n",
            "\n",
            "    accuracy                           0.83      6000\n",
            "   macro avg       0.81      0.79      0.80      6000\n",
            "weighted avg       0.83      0.83      0.83      6000\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}
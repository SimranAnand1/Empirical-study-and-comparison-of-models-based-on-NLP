{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "3.FDA Project Part 3.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python383jvsc74a57bd0e7986c67c6fab0e5b7811717b7be1924f6680ee8c1d523700f68339686c541ab",
      "display_name": "Python 3.8.3 64-bit ('base': conda)"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7HkGBRUVVCgf"
      },
      "source": [
        "#Simran Anand"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eqopdUGXhqyn"
      },
      "source": [
        "# LSTM (Long Short Term Memory Transformer) model for Sentiment Analysis"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dXehGRntffe1",
        "outputId": "fee14279-3b95-452f-97f2-c964592083a7"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from numpy import percentile\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import matplotlib\n",
        "import tweepy\n",
        "from textblob import TextBlob\n",
        "import re # for regular expressions\n",
        "import pandas as pd \n",
        "pd.set_option(\"display.max_colwidth\", 200) \n",
        "import string\n",
        "import requests\n",
        "import nltk # for text manipulation\n",
        "from nltk.stem.porter import *\n",
        "from nltk.tokenize import TweetTokenizer\n",
        "from nltk.corpus import stopwords\n",
        "from nltk import pos_tag, ne_chunk\n",
        "from nltk.sentiment.vader import SentimentIntensityAnalyzer as sid\n",
        "from tqdm import tqdm, notebook\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
        "from tqdm import tqdm\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from scipy import stats \n",
        "from sklearn import metrics \n",
        "from sklearn.metrics import mean_squared_error,mean_absolute_error, make_scorer,classification_report,confusion_matrix,accuracy_score,roc_auc_score,roc_curve\n",
        "from sklearn.model_selection import train_test_split,cross_val_score,KFold\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import f1_score"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 820
        },
        "id": "BUX5GXXLfmeC",
        "outputId": "b18c200b-92a0-4ef7-b803-bb87f5f1b603"
      },
      "source": [
        "df=pd.read_csv(\"https://raw.githubusercontent.com/gabrielpreda/covid-19-tweets/master/covid19_tweets.csv\")\n",
        "df.head()"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         user_name         user_location  \\\n",
              "0           ·èâ·é•‚òª’¨ÍÇÖœÆ            astroworld   \n",
              "1    Tom Basile üá∫üá∏          New York, NY   \n",
              "2  Time4fisticuffs      Pewee Valley, KY   \n",
              "3      ethel mertz  Stuck in the Middle    \n",
              "4         DIPR-J&K     Jammu and Kashmir   \n",
              "\n",
              "                                                                                                                                            user_description  \\\n",
              "0                                                                            wednesday addams as a disney princess keepin it [Ã≤ÃÖ$Ã≤ÃÖ(Ã≤ÃÖŒπŒøŒøÃ≤ÃÖ)Ã≤ÃÖ$Ã≤ÃÖ] üë∏üèªüíö‚ôäÔ∏èüßÄüåµüåÉüåô   \n",
              "1  Husband, Father, Columnist & Commentator. Author of Tough Sell: Fighting the Media War in Iraq. Bush Admin Alum. Newsmax Contributor. Fmr Exec Dir NYSGOP   \n",
              "2                              #Christian #Catholic #Conservative #Reagan #Republican #Capitalist; Sports lover - #BBN #Cincinnati #Reds #Bengals #Trump2020   \n",
              "3                                                                                                      #Browns #Indians #ClevelandProud #[]_[] #Cavs #Resist   \n",
              "4                                                       üñäÔ∏èOfficial Twitter handle of Department of Information and Public Relations, Govt of Jammu & Kashmir   \n",
              "\n",
              "          user_created  user_followers  user_friends  user_favourites  \\\n",
              "0  2017-05-26 05:46:42             624           950            18775   \n",
              "1  2009-04-16 20:06:23            2253          1677               24   \n",
              "2  2009-02-28 18:57:41            9275          9525             7254   \n",
              "3  2019-03-07 01:45:06             197           987             1488   \n",
              "4  2017-02-12 06:45:15          101009           168              101   \n",
              "\n",
              "   user_verified                 date  \\\n",
              "0          False  2020-07-25 12:27:21   \n",
              "1           True  2020-07-25 12:27:17   \n",
              "2          False  2020-07-25 12:27:14   \n",
              "3          False  2020-07-25 12:27:10   \n",
              "4          False  2020-07-25 12:27:08   \n",
              "\n",
              "                                                                                                                                           text  \\\n",
              "0  If I smelled the scent of hand sanitizers today on someone in the past, I would think they were so intoxicated that‚Ä¶ https://t.co/QZvYbrOgb0   \n",
              "1  Hey @Yankees @YankeesPR and @MLB - wouldn't it have made more sense to have the players pay their respects to the A‚Ä¶ https://t.co/1QvW0zgyPu   \n",
              "2  @diane3443 @wdunlap @realDonaldTrump Trump never once claimed #COVID19 was a hoax. We all claim that this effort to‚Ä¶ https://t.co/Jkk8vHWHb3   \n",
              "3   @brookbanktv The one gift #COVID19 has give me is an appreciation for the simple things that were always around me‚Ä¶ https://t.co/Z0pOAlFXcW   \n",
              "4   25 July : Media Bulletin on Novel #CoronaVirusUpdates #COVID19 \\n@kansalrohit69 @DrSyedSehrish @airnewsalerts @ANI‚Ä¶ https://t.co/MN0EEcsJHh   \n",
              "\n",
              "                            hashtags               source  is_retweet  \n",
              "0                                NaN   Twitter for iPhone       False  \n",
              "1                                NaN  Twitter for Android       False  \n",
              "2                        ['COVID19']  Twitter for Android       False  \n",
              "3                        ['COVID19']   Twitter for iPhone       False  \n",
              "4  ['CoronaVirusUpdates', 'COVID19']  Twitter for Android       False  "
            ],
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>user_name</th>\n      <th>user_location</th>\n      <th>user_description</th>\n      <th>user_created</th>\n      <th>user_followers</th>\n      <th>user_friends</th>\n      <th>user_favourites</th>\n      <th>user_verified</th>\n      <th>date</th>\n      <th>text</th>\n      <th>hashtags</th>\n      <th>source</th>\n      <th>is_retweet</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>·èâ·é•‚òª’¨ÍÇÖœÆ</td>\n      <td>astroworld</td>\n      <td>wednesday addams as a disney princess keepin it [Ã≤ÃÖ$Ã≤ÃÖ(Ã≤ÃÖŒπŒøŒøÃ≤ÃÖ)Ã≤ÃÖ$Ã≤ÃÖ] üë∏üèªüíö‚ôäÔ∏èüßÄüåµüåÉüåô</td>\n      <td>2017-05-26 05:46:42</td>\n      <td>624</td>\n      <td>950</td>\n      <td>18775</td>\n      <td>False</td>\n      <td>2020-07-25 12:27:21</td>\n      <td>If I smelled the scent of hand sanitizers today on someone in the past, I would think they were so intoxicated that‚Ä¶ https://t.co/QZvYbrOgb0</td>\n      <td>NaN</td>\n      <td>Twitter for iPhone</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Tom Basile üá∫üá∏</td>\n      <td>New York, NY</td>\n      <td>Husband, Father, Columnist &amp; Commentator. Author of Tough Sell: Fighting the Media War in Iraq. Bush Admin Alum. Newsmax Contributor. Fmr Exec Dir NYSGOP</td>\n      <td>2009-04-16 20:06:23</td>\n      <td>2253</td>\n      <td>1677</td>\n      <td>24</td>\n      <td>True</td>\n      <td>2020-07-25 12:27:17</td>\n      <td>Hey @Yankees @YankeesPR and @MLB - wouldn't it have made more sense to have the players pay their respects to the A‚Ä¶ https://t.co/1QvW0zgyPu</td>\n      <td>NaN</td>\n      <td>Twitter for Android</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Time4fisticuffs</td>\n      <td>Pewee Valley, KY</td>\n      <td>#Christian #Catholic #Conservative #Reagan #Republican #Capitalist; Sports lover - #BBN #Cincinnati #Reds #Bengals #Trump2020</td>\n      <td>2009-02-28 18:57:41</td>\n      <td>9275</td>\n      <td>9525</td>\n      <td>7254</td>\n      <td>False</td>\n      <td>2020-07-25 12:27:14</td>\n      <td>@diane3443 @wdunlap @realDonaldTrump Trump never once claimed #COVID19 was a hoax. We all claim that this effort to‚Ä¶ https://t.co/Jkk8vHWHb3</td>\n      <td>['COVID19']</td>\n      <td>Twitter for Android</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>ethel mertz</td>\n      <td>Stuck in the Middle</td>\n      <td>#Browns #Indians #ClevelandProud #[]_[] #Cavs #Resist</td>\n      <td>2019-03-07 01:45:06</td>\n      <td>197</td>\n      <td>987</td>\n      <td>1488</td>\n      <td>False</td>\n      <td>2020-07-25 12:27:10</td>\n      <td>@brookbanktv The one gift #COVID19 has give me is an appreciation for the simple things that were always around me‚Ä¶ https://t.co/Z0pOAlFXcW</td>\n      <td>['COVID19']</td>\n      <td>Twitter for iPhone</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>DIPR-J&amp;K</td>\n      <td>Jammu and Kashmir</td>\n      <td>üñäÔ∏èOfficial Twitter handle of Department of Information and Public Relations, Govt of Jammu &amp; Kashmir</td>\n      <td>2017-02-12 06:45:15</td>\n      <td>101009</td>\n      <td>168</td>\n      <td>101</td>\n      <td>False</td>\n      <td>2020-07-25 12:27:08</td>\n      <td>25 July : Media Bulletin on Novel #CoronaVirusUpdates #COVID19 \\n@kansalrohit69 @DrSyedSehrish @airnewsalerts @ANI‚Ä¶ https://t.co/MN0EEcsJHh</td>\n      <td>['CoronaVirusUpdates', 'COVID19']</td>\n      <td>Twitter for Android</td>\n      <td>False</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 362
        },
        "id": "F_n6TcYMft3e",
        "outputId": "e2af6c1d-a410-433b-af49-02eedaac8677"
      },
      "source": [
        "# write function for removing @user\n",
        "def remove_pattern(input_txt, pattern):\n",
        "    r = re.findall(pattern, input_txt)\n",
        "    for i in r:\n",
        "        input_txt = re.sub(i,'',input_txt)\n",
        "    return input_txt\n",
        "# create new column with removed @user\n",
        "df['clean_text'] = np.vectorize(remove_pattern)(df['text'], '@[\\w]*')\n",
        "df.head(2)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       user_name user_location  \\\n",
              "0         ·èâ·é•‚òª’¨ÍÇÖœÆ    astroworld   \n",
              "1  Tom Basile üá∫üá∏  New York, NY   \n",
              "\n",
              "                                                                                                                                            user_description  \\\n",
              "0                                                                            wednesday addams as a disney princess keepin it [Ã≤ÃÖ$Ã≤ÃÖ(Ã≤ÃÖŒπŒøŒøÃ≤ÃÖ)Ã≤ÃÖ$Ã≤ÃÖ] üë∏üèªüíö‚ôäÔ∏èüßÄüåµüåÉüåô   \n",
              "1  Husband, Father, Columnist & Commentator. Author of Tough Sell: Fighting the Media War in Iraq. Bush Admin Alum. Newsmax Contributor. Fmr Exec Dir NYSGOP   \n",
              "\n",
              "          user_created  user_followers  user_friends  user_favourites  \\\n",
              "0  2017-05-26 05:46:42             624           950            18775   \n",
              "1  2009-04-16 20:06:23            2253          1677               24   \n",
              "\n",
              "   user_verified                 date  \\\n",
              "0          False  2020-07-25 12:27:21   \n",
              "1           True  2020-07-25 12:27:17   \n",
              "\n",
              "                                                                                                                                           text  \\\n",
              "0  If I smelled the scent of hand sanitizers today on someone in the past, I would think they were so intoxicated that‚Ä¶ https://t.co/QZvYbrOgb0   \n",
              "1  Hey @Yankees @YankeesPR and @MLB - wouldn't it have made more sense to have the players pay their respects to the A‚Ä¶ https://t.co/1QvW0zgyPu   \n",
              "\n",
              "  hashtags               source  is_retweet  \\\n",
              "0      NaN   Twitter for iPhone       False   \n",
              "1      NaN  Twitter for Android       False   \n",
              "\n",
              "                                                                                                                                     clean_text  \n",
              "0  If I smelled the scent of hand sanitizers today on someone in the past, I would think they were so intoxicated that‚Ä¶ https://t.co/QZvYbrOgb0  \n",
              "1                      Hey  PR and  - wouldn't it have made more sense to have the players pay their respects to the A‚Ä¶ https://t.co/1QvW0zgyPu  "
            ],
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>user_name</th>\n      <th>user_location</th>\n      <th>user_description</th>\n      <th>user_created</th>\n      <th>user_followers</th>\n      <th>user_friends</th>\n      <th>user_favourites</th>\n      <th>user_verified</th>\n      <th>date</th>\n      <th>text</th>\n      <th>hashtags</th>\n      <th>source</th>\n      <th>is_retweet</th>\n      <th>clean_text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>·èâ·é•‚òª’¨ÍÇÖœÆ</td>\n      <td>astroworld</td>\n      <td>wednesday addams as a disney princess keepin it [Ã≤ÃÖ$Ã≤ÃÖ(Ã≤ÃÖŒπŒøŒøÃ≤ÃÖ)Ã≤ÃÖ$Ã≤ÃÖ] üë∏üèªüíö‚ôäÔ∏èüßÄüåµüåÉüåô</td>\n      <td>2017-05-26 05:46:42</td>\n      <td>624</td>\n      <td>950</td>\n      <td>18775</td>\n      <td>False</td>\n      <td>2020-07-25 12:27:21</td>\n      <td>If I smelled the scent of hand sanitizers today on someone in the past, I would think they were so intoxicated that‚Ä¶ https://t.co/QZvYbrOgb0</td>\n      <td>NaN</td>\n      <td>Twitter for iPhone</td>\n      <td>False</td>\n      <td>If I smelled the scent of hand sanitizers today on someone in the past, I would think they were so intoxicated that‚Ä¶ https://t.co/QZvYbrOgb0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Tom Basile üá∫üá∏</td>\n      <td>New York, NY</td>\n      <td>Husband, Father, Columnist &amp; Commentator. Author of Tough Sell: Fighting the Media War in Iraq. Bush Admin Alum. Newsmax Contributor. Fmr Exec Dir NYSGOP</td>\n      <td>2009-04-16 20:06:23</td>\n      <td>2253</td>\n      <td>1677</td>\n      <td>24</td>\n      <td>True</td>\n      <td>2020-07-25 12:27:17</td>\n      <td>Hey @Yankees @YankeesPR and @MLB - wouldn't it have made more sense to have the players pay their respects to the A‚Ä¶ https://t.co/1QvW0zgyPu</td>\n      <td>NaN</td>\n      <td>Twitter for Android</td>\n      <td>False</td>\n      <td>Hey  PR and  - wouldn't it have made more sense to have the players pay their respects to the A‚Ä¶ https://t.co/1QvW0zgyPu</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 643
        },
        "id": "xKJlHysSfyl0",
        "outputId": "0901e67d-daa8-457d-d1a3-baabbaa770e3"
      },
      "source": [
        "import re\n",
        "df['clean_text'] = df['clean_text'].apply(lambda x: re.split('https:\\/\\/.*', str(x))[0])\n",
        "df.head(3)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         user_name     user_location  \\\n",
              "0           ·èâ·é•‚òª’¨ÍÇÖœÆ        astroworld   \n",
              "1    Tom Basile üá∫üá∏      New York, NY   \n",
              "2  Time4fisticuffs  Pewee Valley, KY   \n",
              "\n",
              "                                                                                                                                            user_description  \\\n",
              "0                                                                            wednesday addams as a disney princess keepin it [Ã≤ÃÖ$Ã≤ÃÖ(Ã≤ÃÖŒπŒøŒøÃ≤ÃÖ)Ã≤ÃÖ$Ã≤ÃÖ] üë∏üèªüíö‚ôäÔ∏èüßÄüåµüåÉüåô   \n",
              "1  Husband, Father, Columnist & Commentator. Author of Tough Sell: Fighting the Media War in Iraq. Bush Admin Alum. Newsmax Contributor. Fmr Exec Dir NYSGOP   \n",
              "2                              #Christian #Catholic #Conservative #Reagan #Republican #Capitalist; Sports lover - #BBN #Cincinnati #Reds #Bengals #Trump2020   \n",
              "\n",
              "          user_created  user_followers  user_friends  user_favourites  \\\n",
              "0  2017-05-26 05:46:42             624           950            18775   \n",
              "1  2009-04-16 20:06:23            2253          1677               24   \n",
              "2  2009-02-28 18:57:41            9275          9525             7254   \n",
              "\n",
              "   user_verified                 date  \\\n",
              "0          False  2020-07-25 12:27:21   \n",
              "1           True  2020-07-25 12:27:17   \n",
              "2          False  2020-07-25 12:27:14   \n",
              "\n",
              "                                                                                                                                           text  \\\n",
              "0  If I smelled the scent of hand sanitizers today on someone in the past, I would think they were so intoxicated that‚Ä¶ https://t.co/QZvYbrOgb0   \n",
              "1  Hey @Yankees @YankeesPR and @MLB - wouldn't it have made more sense to have the players pay their respects to the A‚Ä¶ https://t.co/1QvW0zgyPu   \n",
              "2  @diane3443 @wdunlap @realDonaldTrump Trump never once claimed #COVID19 was a hoax. We all claim that this effort to‚Ä¶ https://t.co/Jkk8vHWHb3   \n",
              "\n",
              "      hashtags               source  is_retweet  \\\n",
              "0          NaN   Twitter for iPhone       False   \n",
              "1          NaN  Twitter for Android       False   \n",
              "2  ['COVID19']  Twitter for Android       False   \n",
              "\n",
              "                                                                                                              clean_text  \n",
              "0  If I smelled the scent of hand sanitizers today on someone in the past, I would think they were so intoxicated that‚Ä¶   \n",
              "1                      Hey  PR and  - wouldn't it have made more sense to have the players pay their respects to the A‚Ä¶   \n",
              "2                                       Trump never once claimed #COVID19 was a hoax. We all claim that this effort to‚Ä¶   "
            ],
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>user_name</th>\n      <th>user_location</th>\n      <th>user_description</th>\n      <th>user_created</th>\n      <th>user_followers</th>\n      <th>user_friends</th>\n      <th>user_favourites</th>\n      <th>user_verified</th>\n      <th>date</th>\n      <th>text</th>\n      <th>hashtags</th>\n      <th>source</th>\n      <th>is_retweet</th>\n      <th>clean_text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>·èâ·é•‚òª’¨ÍÇÖœÆ</td>\n      <td>astroworld</td>\n      <td>wednesday addams as a disney princess keepin it [Ã≤ÃÖ$Ã≤ÃÖ(Ã≤ÃÖŒπŒøŒøÃ≤ÃÖ)Ã≤ÃÖ$Ã≤ÃÖ] üë∏üèªüíö‚ôäÔ∏èüßÄüåµüåÉüåô</td>\n      <td>2017-05-26 05:46:42</td>\n      <td>624</td>\n      <td>950</td>\n      <td>18775</td>\n      <td>False</td>\n      <td>2020-07-25 12:27:21</td>\n      <td>If I smelled the scent of hand sanitizers today on someone in the past, I would think they were so intoxicated that‚Ä¶ https://t.co/QZvYbrOgb0</td>\n      <td>NaN</td>\n      <td>Twitter for iPhone</td>\n      <td>False</td>\n      <td>If I smelled the scent of hand sanitizers today on someone in the past, I would think they were so intoxicated that‚Ä¶</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Tom Basile üá∫üá∏</td>\n      <td>New York, NY</td>\n      <td>Husband, Father, Columnist &amp; Commentator. Author of Tough Sell: Fighting the Media War in Iraq. Bush Admin Alum. Newsmax Contributor. Fmr Exec Dir NYSGOP</td>\n      <td>2009-04-16 20:06:23</td>\n      <td>2253</td>\n      <td>1677</td>\n      <td>24</td>\n      <td>True</td>\n      <td>2020-07-25 12:27:17</td>\n      <td>Hey @Yankees @YankeesPR and @MLB - wouldn't it have made more sense to have the players pay their respects to the A‚Ä¶ https://t.co/1QvW0zgyPu</td>\n      <td>NaN</td>\n      <td>Twitter for Android</td>\n      <td>False</td>\n      <td>Hey  PR and  - wouldn't it have made more sense to have the players pay their respects to the A‚Ä¶</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Time4fisticuffs</td>\n      <td>Pewee Valley, KY</td>\n      <td>#Christian #Catholic #Conservative #Reagan #Republican #Capitalist; Sports lover - #BBN #Cincinnati #Reds #Bengals #Trump2020</td>\n      <td>2009-02-28 18:57:41</td>\n      <td>9275</td>\n      <td>9525</td>\n      <td>7254</td>\n      <td>False</td>\n      <td>2020-07-25 12:27:14</td>\n      <td>@diane3443 @wdunlap @realDonaldTrump Trump never once claimed #COVID19 was a hoax. We all claim that this effort to‚Ä¶ https://t.co/Jkk8vHWHb3</td>\n      <td>['COVID19']</td>\n      <td>Twitter for Android</td>\n      <td>False</td>\n      <td>Trump never once claimed #COVID19 was a hoax. We all claim that this effort to‚Ä¶</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P28pe1dXfzWD"
      },
      "source": [
        "# remove special characters, numbers, punctuations\n",
        "df['clean_text'] = df['clean_text'].str.replace('[^a-zA-Z#]+',' ')"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 429
        },
        "id": "hVHzodfOf3f0",
        "outputId": "4742ee5f-6379-45cb-a0bf-b512eacbd38c"
      },
      "source": [
        "# remove short words\n",
        "df['clean_text'] = df['clean_text'].apply(lambda x: ' '.join([w for w in x.split() if len(w) > 2]))\n",
        "df.head(2)\n",
        "# create new variable tokenized tweet \n",
        "tokenized_tweet = df['clean_text'].apply(lambda x: x.split())\n",
        "df.head(2)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       user_name user_location  \\\n",
              "0         ·èâ·é•‚òª’¨ÍÇÖœÆ    astroworld   \n",
              "1  Tom Basile üá∫üá∏  New York, NY   \n",
              "\n",
              "                                                                                                                                            user_description  \\\n",
              "0                                                                            wednesday addams as a disney princess keepin it [Ã≤ÃÖ$Ã≤ÃÖ(Ã≤ÃÖŒπŒøŒøÃ≤ÃÖ)Ã≤ÃÖ$Ã≤ÃÖ] üë∏üèªüíö‚ôäÔ∏èüßÄüåµüåÉüåô   \n",
              "1  Husband, Father, Columnist & Commentator. Author of Tough Sell: Fighting the Media War in Iraq. Bush Admin Alum. Newsmax Contributor. Fmr Exec Dir NYSGOP   \n",
              "\n",
              "          user_created  user_followers  user_friends  user_favourites  \\\n",
              "0  2017-05-26 05:46:42             624           950            18775   \n",
              "1  2009-04-16 20:06:23            2253          1677               24   \n",
              "\n",
              "   user_verified                 date  \\\n",
              "0          False  2020-07-25 12:27:21   \n",
              "1           True  2020-07-25 12:27:17   \n",
              "\n",
              "                                                                                                                                           text  \\\n",
              "0  If I smelled the scent of hand sanitizers today on someone in the past, I would think they were so intoxicated that‚Ä¶ https://t.co/QZvYbrOgb0   \n",
              "1  Hey @Yankees @YankeesPR and @MLB - wouldn't it have made more sense to have the players pay their respects to the A‚Ä¶ https://t.co/1QvW0zgyPu   \n",
              "\n",
              "  hashtags               source  is_retweet  \\\n",
              "0      NaN   Twitter for iPhone       False   \n",
              "1      NaN  Twitter for Android       False   \n",
              "\n",
              "                                                                                        clean_text  \n",
              "0  smelled the scent hand sanitizers today someone the past would think they were intoxicated that  \n",
              "1                      Hey and wouldn have made more sense have the players pay their respects the  "
            ],
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>user_name</th>\n      <th>user_location</th>\n      <th>user_description</th>\n      <th>user_created</th>\n      <th>user_followers</th>\n      <th>user_friends</th>\n      <th>user_favourites</th>\n      <th>user_verified</th>\n      <th>date</th>\n      <th>text</th>\n      <th>hashtags</th>\n      <th>source</th>\n      <th>is_retweet</th>\n      <th>clean_text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>·èâ·é•‚òª’¨ÍÇÖœÆ</td>\n      <td>astroworld</td>\n      <td>wednesday addams as a disney princess keepin it [Ã≤ÃÖ$Ã≤ÃÖ(Ã≤ÃÖŒπŒøŒøÃ≤ÃÖ)Ã≤ÃÖ$Ã≤ÃÖ] üë∏üèªüíö‚ôäÔ∏èüßÄüåµüåÉüåô</td>\n      <td>2017-05-26 05:46:42</td>\n      <td>624</td>\n      <td>950</td>\n      <td>18775</td>\n      <td>False</td>\n      <td>2020-07-25 12:27:21</td>\n      <td>If I smelled the scent of hand sanitizers today on someone in the past, I would think they were so intoxicated that‚Ä¶ https://t.co/QZvYbrOgb0</td>\n      <td>NaN</td>\n      <td>Twitter for iPhone</td>\n      <td>False</td>\n      <td>smelled the scent hand sanitizers today someone the past would think they were intoxicated that</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Tom Basile üá∫üá∏</td>\n      <td>New York, NY</td>\n      <td>Husband, Father, Columnist &amp; Commentator. Author of Tough Sell: Fighting the Media War in Iraq. Bush Admin Alum. Newsmax Contributor. Fmr Exec Dir NYSGOP</td>\n      <td>2009-04-16 20:06:23</td>\n      <td>2253</td>\n      <td>1677</td>\n      <td>24</td>\n      <td>True</td>\n      <td>2020-07-25 12:27:17</td>\n      <td>Hey @Yankees @YankeesPR and @MLB - wouldn't it have made more sense to have the players pay their respects to the A‚Ä¶ https://t.co/1QvW0zgyPu</td>\n      <td>NaN</td>\n      <td>Twitter for Android</td>\n      <td>False</td>\n      <td>Hey and wouldn have made more sense have the players pay their respects the</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LZN6IFvWf_xz"
      },
      "source": [
        "from nltk.stem.porter import *\n",
        "stemmer = PorterStemmer()\n",
        "# apply stemmer for tokenized_tweet\n",
        "tokenized_tweet = tokenized_tweet.apply(lambda x: [stemmer.stem(i) for i in x])"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b2ciNzBegERK"
      },
      "source": [
        "# join tokens into one sentence\n",
        "for i in range(len(tokenized_tweet)):\n",
        "    tokenized_tweet[i] = ' '.join(tokenized_tweet[i])\n",
        "# change df['clean_text'] to tokenized_tweet"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ka2Zl5hUgHzm"
      },
      "source": [
        "df['clean_text']  = tokenized_tweet"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_LHpTfb1gKm-",
        "outputId": "791031d7-9b3e-4543-ba1c-4fc77704726e"
      },
      "source": [
        "nltk.download('stopwords')"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to\n[nltk_data]     C:\\Users\\simmu\\AppData\\Roaming\\nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hu9ygAZ8gORm"
      },
      "source": [
        "from nltk.corpus import stopwords\n",
        "stop = stopwords.words('english')"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nu_QVZN6gQUf",
        "outputId": "f10e32c5-c812-4eb5-d01a-8191453e2e0f"
      },
      "source": [
        "df['clean_text'].apply(lambda x: [item for item in x if item not in stop])"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0                           [e, l, l,  , h, e,  , c, e, n,  , h, n,  , n,  ,  , e, n,  , h, e,  , p,  , w, u, l,  , h, n, k,  , h, e,  , w, e, r, e,  , n, x,  , h]\n",
              "1                  [h, e,  , n,  , w, u, l, n,  , h, v, e,  , e,  , r, e,  , e, n,  , h, v, e,  , h, e,  , p, l, e, r,  , p,  , h, e, r,  , r, e, p, e, c,  , h, e]\n",
              "2                                             [r, u, p,  , n, e, v, e, r,  , n, c,  , c, l,  , #, c, v,  , w,  , h, x,  , l, l,  , c, l,  , h,  , h,  , e, f, f, r]\n",
              "3         [h, e,  , n, e,  , g, f,  , #, c, v,  , h,  , g, v, e,  , p, p, r, e, c,  , f, r,  , h, e,  , p, l,  , h, n, g,  , h,  , w, e, r, e,  , l, w,  , r, u, n]\n",
              "4                                                                     [j, u, l,  , e,  , b, u, l, l, e, n,  , n, v, e, l,  , #, c, r, n, v, r, u, u, p,  , #, c, v]\n",
              "                                                                                    ...                                                                            \n",
              "179103                                                             [h, n, k,  , f, r,  , n, n,  , f, r,  , h, e,  , #, w, e, r, k,  , c, h, l, l, e, n, g,  , n, n]\n",
              "179104                                                                                                                [h, e,  , e, r,  , n, n,  , l, l,  , #, c, v]\n",
              "179105             [p, w, e, r,  , p, n,  , j, u, n,  , l, u, c, e, n,  , r, b, u,  , h, e,  , g, r, n, p, r,  , w, h,  , e,  , c, v,  , n,  , h, e,  , g, r, n, c]\n",
              "179106                                                 [r, e,  , h, n,  , u, e, n,  , e,  , p,  , f, r,  , #, c, v,  , j, r,  , u, n, v, e, r,  , b, c,  , n, e, w]\n",
              "179107                                                                                                                            [p,  , w, h, e, n,  , e, e,  , p]\n",
              "Name: clean_text, Length: 179108, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XLeiblNWgSjF"
      },
      "source": [
        "#creates a function that determines subjectivity and polarity from the textblob package\n",
        "def getTextSubjectivity(clean_text):\n",
        "    return TextBlob(clean_text).sentiment.subjectivity\n",
        "def getTextPolarity(clean_text):\n",
        "    return TextBlob(clean_text).sentiment.polarity\n",
        "#applies these functions to the dataframe\n",
        "df['Subjectivity'] = df['clean_text'].apply(getTextSubjectivity)\n",
        "df['Polarity'] = df['clean_text'].apply(getTextPolarity)\n",
        "#builds a function to calculate and categorize each tweet as Negative, Neutral, and Positive\n",
        "def getTextAnalysis(a):\n",
        "    if a < 0:\n",
        "        return \"Negative\"\n",
        "    elif a == 0:\n",
        "        return \"Neutral\"\n",
        "    else:\n",
        "        return \"Positive\"\n",
        "#creates another column called Score and applies the function to the dataframe\n",
        "df['Score'] = df['Polarity'].apply(getTextAnalysis)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Spfcc-PogW5g"
      },
      "source": [
        "new_df=df[['clean_text','Score']]"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S48DPundga9y"
      },
      "source": [
        "data=new_df.head(20000)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oAwo3308ghTn"
      },
      "source": [
        "## LSTM Neural Network using Keras (RNN using tanh and sigmoid activation functions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_11\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_11 (Embedding)     (None, 16188, 128)        2560000   \n",
            "_________________________________________________________________\n",
            "lstm_11 (LSTM)               (None, 128)               131584    \n",
            "_________________________________________________________________\n",
            "dense_11 (Dense)             (None, 1)                 129       \n",
            "=================================================================\n",
            "Total params: 2,691,713\n",
            "Trainable params: 2,691,713\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Training accuracy Score    :  0.9998125\n",
            "Validation accuracy Score :  0.8145\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    Negative       0.68      0.71      0.69       583\n",
            "     Neutral       0.86      0.86      0.86      2038\n",
            "    Positive       0.81      0.80      0.80      1379\n",
            "\n",
            "    accuracy                           0.81      4000\n",
            "   macro avg       0.78      0.79      0.78      4000\n",
            "weighted avg       0.82      0.81      0.81      4000\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "\"\"\"Loading the Dataset\"\"\"\n",
        "\n",
        "#from tensorflow.keras.datasets import imdb\n",
        "\n",
        "\"\"\"### **Data Preprocessing**\"\"\"\n",
        "\n",
        "words=20000\n",
        "max_length=100\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train,valid = train_test_split(data,test_size = 0.2,random_state=0,stratify = data.Score.values)\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from nltk.corpus import stopwords\n",
        "stop = list(stopwords.words('english'))\n",
        "vectorizer = CountVectorizer(decode_error = 'replace',stop_words = stop)\n",
        "\n",
        "x_train = vectorizer.fit_transform(train.clean_text.values)\n",
        "x_valid = vectorizer.transform(valid.clean_text.values)\n",
        "\n",
        "y_train = train.Score.values\n",
        "y_valid = valid.Score.values\n",
        "\n",
        "\"\"\"Padding the Text\"\"\"\n",
        "\n",
        "#x_train = tf.keras.preprocessing.sequence.pad_sequences(x_train.todense, maxlen=max_length)\n",
        "\n",
        "#x_valid = tf.keras.preprocessing.sequence.pad_sequences(x_valid.todense, maxlen=max_length)\n",
        "\n",
        "word_size=words\n",
        "word_size\n",
        "\n",
        "embed_size=128\n",
        "\n",
        "\"\"\"### Building a Recurrent Neural Network\"\"\"\n",
        "\n",
        "data_model=tf.keras.Sequential()\n",
        "\n",
        "# Embedding Layer\n",
        "data_model.add(tf.keras.layers.Embedding(word_size, embed_size, input_shape=(x_train.shape[1],)))\n",
        "\n",
        "# LSTM Layer\n",
        "data_model.add(tf.keras.layers.LSTM(units=128, activation='tanh'))\n",
        "\n",
        "# Output Layer\n",
        "data_model.add(tf.keras.layers.Dense(units=1, activation='sigmoid'))\n",
        "\n",
        "data_model.summary()\n",
        "\n",
        "\"\"\"#### Compiling the model\"\"\"\n",
        "\n",
        "data_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "\"\"\"#### Training the model\"\"\"\n",
        "\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "mlp = MLPClassifier(hidden_layer_sizes=(10, 10, 10), max_iter=1000)\n",
        "mlp.fit(x_train, y_train)\n",
        "predictions = mlp.predict(x_valid)\n",
        "accuracy = accuracy_score(y_valid,predictions)\n",
        "print(\"Training accuracy Score    : \",mlp.score(x_train,y_train))\n",
        "print(\"Validation accuracy Score : \",accuracy )\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "print(classification_report(y_valid,predictions))"
      ]
    },
    {
      "source": [
        "## LSTM model (RNN using softmax activation function with Regularization)"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DH29CkOhht5D"
      },
      "source": [
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Embedding, LSTM, SpatialDropout1D\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.utils.np_utils import to_categorical\n",
        "from sklearn.utils import resample\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.metrics import confusion_matrix,classification_report"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7myBqMCsl18i"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train,valid = train_test_split(data,test_size = 0.3,random_state=0,stratify = data.Score.values) #stratification means that the train_test_split method returns training and test subsets that have the same proportions of class labels as the input dataset."
      ],
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rYr2rH6Jll-k"
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from nltk.corpus import stopwords\n",
        "stop = list(stopwords.words('english'))\n",
        "vectorizer = CountVectorizer(decode_error = 'replace',stop_words = stop)\n",
        "\n",
        "X_train = vectorizer.fit_transform(train.clean_text.values)\n",
        "X_valid = vectorizer.transform(valid.clean_text.values)\n",
        "\n",
        "Y_train = train.Score.values\n",
        "Y_valid = valid.Score.values"
      ],
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0fSCpFdDfAVm",
        "outputId": "77ee5839-3e8d-40b4-81a3-0b8dbec8276e"
      },
      "source": [
        "# model\n",
        "embed_dim = 128\n",
        "lstm_out = 192\n",
        "max_fatures = 2000\n",
        "model = Sequential()\n",
        "model.add(Embedding(max_fatures, embed_dim,input_length = X_train.shape[1]))\n",
        "model.add(SpatialDropout1D(0.4))\n",
        "model.add(LSTM(lstm_out, dropout=0.4, recurrent_dropout=0.4))\n",
        "model.add(Dense(2,activation='softmax'))\n",
        "model.compile(loss = 'categorical_crossentropy', optimizer='adam',metrics = ['accuracy'])\n",
        "print(model.summary())"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_2\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nembedding_2 (Embedding)      (None, 15056, 128)        256000    \n_________________________________________________________________\nspatial_dropout1d_2 (Spatial (None, 15056, 128)        0         \n_________________________________________________________________\nlstm_2 (LSTM)                (None, 192)               246528    \n_________________________________________________________________\ndense_2 (Dense)              (None, 2)                 386       \n=================================================================\nTotal params: 502,914\nTrainable params: 502,914\nNon-trainable params: 0\n_________________________________________________________________\nNone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uSiG9nCZn2jO",
        "outputId": "0f580c5a-885c-4757-fd79-c2542c705c62"
      },
      "source": [
        "from sklearn.neural_network import MLPClassifier\n",
        "mlp = MLPClassifier(hidden_layer_sizes=(10, 10, 10), max_iter=1000)\n",
        "mlp.fit(X_train, Y_train)\n",
        "predictions = mlp.predict(X_valid)\n",
        "accuracy = accuracy_score(Y_valid,predictions)\n",
        "print(\"Training accuracy Score    : \",mlp.score(X_train,Y_train))\n",
        "print(\"Validation accuracy Score : \",accuracy )\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "print(classification_report(Y_valid,predictions))"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training accuracy Score    :  0.9998571428571429\nValidation accuracy Score :  0.8263333333333334\n              precision    recall  f1-score   support\n\n    Negative       0.80      0.63      0.70       875\n     Neutral       0.86      0.87      0.87      3056\n    Positive       0.79      0.84      0.81      2069\n\n    accuracy                           0.83      6000\n   macro avg       0.81      0.78      0.79      6000\nweighted avg       0.83      0.83      0.82      6000\n\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ]
}